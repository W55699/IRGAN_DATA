{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "\n",
    "from model import Generator, Discriminator\n",
    "from config import irgan_config\n",
    "from data_utils_1 import RecDataset, DataProvider\n",
    "from evaluation.rec_evaluator import RecEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = irgan_config.epochs\n",
    "batch_size = irgan_config.batch_size\n",
    "epochs_d = irgan_config.epochs_d\n",
    "epochs_g = irgan_config.epochs_g\n",
    "emb_dim = irgan_config.emb_dim\n",
    "eta_G = irgan_config.eta_G\n",
    "eta_D = irgan_config.eta_D\n",
    "device = irgan_config.device\n",
    "weight_decay_g = irgan_config.weight_decay_g\n",
    "weight_decay_d = irgan_config.weight_decay_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters and datset-specific parameters\n",
    "rec_dataset = RecDataset(\"./data/worldnews/\")\n",
    "all_users = rec_dataset.get_users()\n",
    "all_items = rec_dataset.get_items()\n",
    "num_users = rec_dataset.get_num_users()\n",
    "num_items = rec_dataset.get_num_items()\n",
    "bought_mask = rec_dataset.get_bought_mask().to(device)\n",
    "eval_dict = rec_dataset.get_interaction_records(\"test\")\n",
    "train_ui = rec_dataset.get_user_item_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProvider(device)\n",
    "evaluator = RecEvaluator(eval_dict, None, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(num_users, num_items, emb_dim, bought_mask)\n",
    "D = Discriminator(num_users, num_items, emb_dim)\n",
    "G = G.to(device)\n",
    "D = D.to(device)\n",
    "\n",
    "loss_D = nn.BCELoss()\n",
    "optimizer_G = torch.optim.SGD(G.parameters(), momentum = 0.9, lr = eta_G)\n",
    "optimizer_D = torch.optim.SGD(D.parameters(), momentum = 0.9, lr = eta_D, weight_decay = weight_decay_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print(\n",
    "            \"[Epoch %d/%d]\"\n",
    "            % (epoch+1, 10)\n",
    "        )  \n",
    "    time_epoch_start = time.time()\n",
    "    \n",
    "    # ---------------------\n",
    "    #  Train Discriminator\n",
    "    # ---------------------   \n",
    "    D.train()\n",
    "    G.eval()\n",
    "    for epoch_d in range(epochs_d):\n",
    "        time_d_start = time.time()\n",
    "        if(epoch_d % 5 == 0):\n",
    "            train_set_d = dp.prepare_data_for_discriminator(G, train_ui, batch_size = batch_size)\n",
    "        loss_d_epoch = 0\n",
    "        for users, items, labels in train_set_d:\n",
    "            dis_score = D(users,items)\n",
    "            loss_d = loss_D(dis_score, labels)\n",
    "            loss_d_epoch += loss_d.item()\n",
    "            optimizer_D.zero_grad()\n",
    "            loss_d.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "        time_d_end = time.time()\n",
    "        loss_d_epoch /= len(train_set_d)\n",
    "        print(\n",
    "            \"\\t[Discriminator][Epochs %d/%d] [D epoch loss: %6.5f] [Time:%6.5f] \"\n",
    "            % (epoch_d+1, epochs_d, loss_d_epoch, time_d_end - time_d_start)\n",
    "        )\n",
    "       \n",
    "        with torch.no_grad():\n",
    "\n",
    "            torch.save(D.state_dict(),\"./pretrained_models/worldnews/pretrained_model_discriminator.pkl\")\n",
    "        \n",
    "    # --------------------- \n",
    "    #  Train Generator\n",
    "    #\n",
    "    # For generator\n",
    "    #   Generate K user-item pairs\n",
    "    #   Leveraging Policy Gradient to update parameters of generator\n",
    "    #\n",
    "    # --------------------- \n",
    "    D.eval()\n",
    "    G.train()\n",
    "    for epoch_g in range(epochs_g):\n",
    "        time_g_start = time.time()\n",
    "        train_set_g = dp.prepare_data_for_generator(all_users, batch_size)\n",
    "        loss_g_epoch = 0\n",
    "        for fake_users, in train_set_g:\n",
    "            fake_items, fake_probs, fake_p_n = G.sample_items_for_users(fake_users, k = 256,\\\n",
    "                                                                        temperature=1, lambda_bought=0.2)\n",
    "            fake_users = fake_users.view(-1,1).expand_as(fake_items).contiguous()\n",
    "            fake_users = fake_users.view(-1)\n",
    "            fake_items = fake_items.view(-1)\n",
    "            fake_probs = fake_probs.view(-1)\n",
    "            fake_p_n = fake_p_n.view(-1)\n",
    "            \n",
    "            log_fake_probs = torch.log(fake_probs.clamp(1e-8))\n",
    "            fake_probs = fake_probs.detach()\n",
    "            fake_p_n = fake_p_n.detach()\n",
    "            \n",
    "            reward = (2 * D(fake_users, fake_items) - 1).detach()*(fake_probs/fake_p_n)\n",
    "            loss_g = -torch.mean(log_fake_probs*reward)\n",
    "            loss_g_epoch += loss_g\n",
    "            \n",
    "            optimizer_G.zero_grad()  \n",
    "            loss_g.backward() \n",
    "            optimizer_G.step()\n",
    "        time_g_end = time.time()\n",
    "        print(\n",
    "            \"\\t[Generator][Epochs %d/%d] [G epoch loss: %6.5f] [Time:%6.5f]\"\n",
    "            % (epoch_g + 1, epochs_g, loss_g_epoch, time_g_end - time_g_start )\n",
    "        ) \n",
    "     \n",
    "        with torch.no_grad():\n",
    "\n",
    "            torch.save(G.state_dict(),\"./pretrained_models/worldnews/pretrained_model_generator.pkl\")\n",
    "    time_epoch_end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
